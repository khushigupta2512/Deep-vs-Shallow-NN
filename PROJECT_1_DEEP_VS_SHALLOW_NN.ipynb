{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4m136eleTHH"
      },
      "outputs": [],
      "source": [
        "from torch import nn, save, load\n",
        "import torch\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "XKT7AbK9eYlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader #load dataset from pytorch"
      ],
      "metadata": {
        "id": "h9qd448R7w8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets  "
      ],
      "metadata": {
        "id": "QxDEInlCeYw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToTensor #convert image to tensor"
      ],
      "metadata": {
        "id": "Nb62G5ZKeY0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get data\n",
        "\n",
        "train = datasets.MNIST(root=\"data\", download=True, train=True, transform=ToTensor()) #10 classes-> 0-9\n",
        "train_loader=DataLoader(train,32) #32-> batches of 32\n",
        "test = datasets.MNIST(root=\"data\", download=True, train=False, transform=ToTensor()) #10 classes-> 0-9\n",
        "test_loader=DataLoader(train,32) #32-> batches of 32"
      ],
      "metadata": {
        "id": "JtFM57oIeY3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() #subclass this model\n",
        "    self.model= nn.Sequential(  #all layers are defined here\n",
        "        nn.Conv2d(1,32,(3,3)), #1-> black nd white images, 32-> batch, 3*3-> size\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,64,(3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,64,(3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(64*(28-6)*(28-6), 10)     # (28-6)-> in each layer we'll be shaping 2 pixel from width and height-> 6---> final size-> 1*28*28-> 10 O/P-> 10 classes\n",
        "    \n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "#INSTANCE OF NN, LOSS, OPTIMIZER\n",
        "clf = ImageClassifier().to('cuda') #extending to GPU\n",
        "opt = Adam(clf.parameters(), lr=1e-3)\n",
        "loss_fn= nn.CrossEntropyLoss()\n",
        "\n",
        "#Training Flow\n",
        "if __name__ == \"__main__\":\n",
        "  for epoch in range(10):\n",
        "    for batch in train_loader:\n",
        "      X,y= batch\n",
        "      X,y=X.to('cuda'), y.to('cuda')\n",
        "      yhat=clf(X) #prediction\n",
        "      loss= loss_fn(yhat,y)\n",
        "\n",
        "      #apply backpropagation\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step() #gradient descent\n",
        "\n",
        "    print(f\"Epoch:{epoch} loss is {loss.item()}\")\n",
        "    with open ('model_state.pt','wb') as f:\n",
        "      save(clf.state_dict(),f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbvQ01eueY6x",
        "outputId": "ff0fa36c-201d-4dde-e872-036a4df2da2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 loss is 0.11470768600702286\n",
            "Epoch:1 loss is 0.0026096345391124487\n",
            "Epoch:2 loss is 0.0019300616113469005\n",
            "Epoch:3 loss is 6.27452100161463e-05\n",
            "Epoch:4 loss is 2.822665192070417e-05\n",
            "Epoch:5 loss is 8.82285603438504e-05\n",
            "Epoch:6 loss is 4.100267688045278e-05\n",
            "Epoch:7 loss is 4.518685727816774e-06\n",
            "Epoch:8 loss is 0.000560738320928067\n",
            "Epoch:9 loss is 2.1606624045489298e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier_nohid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() #subclass this model\n",
        "    self.model= nn.Sequential(  #all layers are defined here\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, 10)     # (28-6)-> in each layer we'll be shaping 2 pixel from width and height-> 6---> final size-> 1*28*28-> 10 O/P-> 10 classes\n",
        "    \n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "#INSTANCE OF NN, LOSS, OPTIMIZER\n",
        "clf = ImageClassifier().to('cuda') #extending to GPU\n",
        "opt = Adam(clf.parameters(), lr=1e-3)\n",
        "loss_fn= nn.CrossEntropyLoss()\n",
        "\n",
        "#Training Flow\n",
        "if __name__ == \"__main__\":\n",
        "  for epoch in range(10):\n",
        "    train_accuracy=0\n",
        "    for batch in train_loader:\n",
        "      X,y= batch\n",
        "      X,y=X.to('cuda'), y.to('cuda')\n",
        "      yhat=clf(X) #prediction\n",
        "      loss= loss_fn(yhat,y)\n",
        "      yhat = yhat.data.max(dim=1, keepdim=True)[1]\n",
        "      train_accuracy += yhat.eq(y.data.view_as(yhat)).cpu().sum()\n",
        "\n",
        "      #apply backpropagation\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step() #gradient descent\n",
        "\n",
        "    train_accuracy = train_accuracy/len(train_loader.dataset)*100\n",
        "    print(f\"Epoch:{epoch} loss is {loss.item()}, train accuracy is {train_accuracy}\")\n",
        "    with open ('model_state.pt','wb') as f:\n",
        "      save(clf.state_dict(),f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38000295-eac8-440c-8ed0-26a62b102d56",
        "id": "tsZ8yyoE34uu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 loss is 0.031427960842847824, train accuracy is 96.19499969482422\n",
            "Epoch:1 loss is 0.0009594273869879544, train accuracy is 98.63500213623047\n",
            "Epoch:2 loss is 0.0009347838349640369, train accuracy is 99.17500305175781\n",
            "Epoch:3 loss is 0.0016275722300633788, train accuracy is 99.42832946777344\n",
            "Epoch:4 loss is 7.979183465067763e-06, train accuracy is 99.5816650390625\n",
            "Epoch:5 loss is 3.9447626477340236e-05, train accuracy is 99.67832946777344\n",
            "Epoch:6 loss is 7.092548003129195e-06, train accuracy is 99.72166442871094\n",
            "Epoch:7 loss is 4.928247108182404e-06, train accuracy is 99.76499938964844\n",
            "Epoch:8 loss is 1.6726382909837412e-06, train accuracy is 99.78500366210938\n",
            "Epoch:9 loss is 5.364385629036406e-07, train accuracy is 99.79833221435547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier_onehid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() #subclass this model\n",
        "    self.model= nn.Sequential(  #all layers are defined here\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, 500),     # (28-6)-> in each layer we'll be shaping 2 pixel from width and height-> 6---> final size-> 1*28*28-> 10 O/P-> 10 classes\n",
        "        nn.Linear(500,10)\n",
        "    \n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "#INSTANCE OF NN, LOSS, OPTIMIZER\n",
        "clf = ImageClassifier().to('cuda') #extending to GPU\n",
        "opt = Adam(clf.parameters(), lr=1e-3)\n",
        "loss_fn= nn.CrossEntropyLoss()\n",
        "\n",
        "#Training Flow\n",
        "if __name__ == \"__main__\":\n",
        "  for epoch in range(10):\n",
        "    train_accuracy=0\n",
        "    for batch in train_loader:\n",
        "      X,y= batch\n",
        "      X,y=X.to('cuda'), y.to('cuda')\n",
        "      yhat=clf(X) #prediction\n",
        "      loss= loss_fn(yhat,y)\n",
        "      yhat = yhat.data.max(dim=1, keepdim=True)[1]\n",
        "      train_accuracy += yhat.eq(y.data.view_as(yhat)).cpu().sum()\n",
        "\n",
        "      #apply backpropagation\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step() #gradient descent\n",
        "\n",
        "    train_accuracy = train_accuracy/len(train_loader.dataset)*100\n",
        "    print(f\"Epoch:{epoch} loss is {loss.item()}, train accuracy is {train_accuracy}\")\n",
        "    with open ('model_state.pt','wb') as f:\n",
        "      save(clf.state_dict(),f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5a23a3-bc57-49dd-a90b-625cedb55584",
        "id": "LJY7ZwG04R-O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 loss is 0.0222284235060215, train accuracy is 95.85000610351562\n",
            "Epoch:1 loss is 0.0014848064165562391, train accuracy is 98.55833435058594\n",
            "Epoch:2 loss is 0.0005562488222494721, train accuracy is 99.1550064086914\n",
            "Epoch:3 loss is 7.533289317507297e-05, train accuracy is 99.38666534423828\n",
            "Epoch:4 loss is 2.938209581770934e-05, train accuracy is 99.55000305175781\n",
            "Epoch:5 loss is 4.899513805867173e-05, train accuracy is 99.64500427246094\n",
            "Epoch:6 loss is 2.348536509089172e-05, train accuracy is 99.72833251953125\n",
            "Epoch:7 loss is 0.00032784478389658034, train accuracy is 99.77833557128906\n",
            "Epoch:8 loss is 6.119492172729224e-05, train accuracy is 99.81333923339844\n",
            "Epoch:9 loss is 3.532365371938795e-05, train accuracy is 99.81666564941406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier_twohid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() #subclass this model\n",
        "    self.model= nn.Sequential(  #all layers are defined here\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, 200),     # (28-6)-> in each layer we'll be shaping 2 pixel from width and height-> 6---> final size-> 1*28*28-> 10 O/P-> 10 classes\n",
        "        nn.Linear(200,300),\n",
        "        nn.Linear(300,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "#INSTANCE OF NN, LOSS, OPTIMIZER\n",
        "clf = ImageClassifier().to('cuda') #extending to GPU\n",
        "opt = Adam(clf.parameters(), lr=1e-3)\n",
        "loss_fn= nn.CrossEntropyLoss()\n",
        "\n",
        "##Training Flow\n",
        "if __name__ == \"__main__\":\n",
        "  for epoch in range(10):\n",
        "    train_accuracy=0\n",
        "    for batch in train_loader:\n",
        "      X,y= batch\n",
        "      X,y=X.to('cuda'), y.to('cuda')\n",
        "      yhat=clf(X) #prediction\n",
        "      loss= loss_fn(yhat,y)\n",
        "      yhat = yhat.data.max(dim=1, keepdim=True)[1]\n",
        "      train_accuracy += yhat.eq(y.data.view_as(yhat)).cpu().sum()\n",
        "\n",
        "      #apply backpropagation\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step() #gradient descent\n",
        "\n",
        "    train_accuracy = train_accuracy/len(train_loader.dataset)*100\n",
        "    print(f\"Epoch:{epoch} loss is {loss.item()}, train accuracy is {train_accuracy}\")\n",
        "    with open ('model_state.pt','wb') as f:\n",
        "      save(clf.state_dict(),f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7ea13f-6ecc-4c7b-f28a-c8472c91972f",
        "id": "5dYTj1Uq8qbz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 loss is 0.047737542539834976, train accuracy is 96.20500183105469\n",
            "Epoch:1 loss is 0.0020163198933005333, train accuracy is 98.63999938964844\n",
            "Epoch:2 loss is 0.00024294460308738053, train accuracy is 99.1933364868164\n",
            "Epoch:3 loss is 0.00012687566049862653, train accuracy is 99.375\n",
            "Epoch:4 loss is 0.00039435282815247774, train accuracy is 99.55333709716797\n",
            "Epoch:5 loss is 9.561596925777849e-06, train accuracy is 99.67832946777344\n",
            "Epoch:6 loss is 0.00037592771695926785, train accuracy is 99.6883316040039\n",
            "Epoch:7 loss is 1.13874575617956e-05, train accuracy is 99.788330078125\n",
            "Epoch:8 loss is 3.9487906633439707e-07, train accuracy is 99.77166748046875\n",
            "Epoch:9 loss is 3.661833943624515e-06, train accuracy is 99.8066635131836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier_threehid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() #subclass this model\n",
        "    self.model= nn.Sequential(  #all layers are defined here\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, 125),    # (28-6)-> in each layer we'll be shaping 2 pixel from width and height-> 6---> final size-> 1*28*28-> 10 O/P-> 10 classes\n",
        "        nn.Linear(125,250),\n",
        "        nn.Linear(250,125),\n",
        "        nn.Linear(125,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "#INSTANCE OF NN, LOSS, OPTIMIZER\n",
        "clf = ImageClassifier().to('cuda') #extending to GPU\n",
        "opt = Adam(clf.parameters(), lr=1e-3)\n",
        "loss_fn= nn.CrossEntropyLoss()\n",
        "\n",
        "#Training Flow\n",
        "if __name__ == \"__main__\":\n",
        "  for epoch in range(10):\n",
        "    train_accuracy=0\n",
        "    for batch in train_loader:\n",
        "      X,y= batch\n",
        "      X,y=X.to('cuda'), y.to('cuda')\n",
        "      yhat=clf(X) #prediction\n",
        "      loss= loss_fn(yhat,y)\n",
        "      yhat = yhat.data.max(dim=1, keepdim=True)[1]\n",
        "      train_accuracy += yhat.eq(y.data.view_as(yhat)).cpu().sum()\n",
        "\n",
        "      #apply backpropagation\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step() #gradient descent\n",
        "\n",
        "    train_accuracy = train_accuracy/len(train_loader.dataset)*100\n",
        "    print(f\"Epoch:{epoch} loss is {loss.item()}, train accuracy is {train_accuracy}\")\n",
        "    with open ('model_state.pt','wb') as f:\n",
        "      save(clf.state_dict(),f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d088e2-7b3e-4bbf-c8f1-7ad51ffca7b7",
        "id": "0DZOT_o18zh6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 loss is 0.01179519947618246, train accuracy is 96.2066650390625\n",
            "Epoch:1 loss is 0.0044312491081655025, train accuracy is 98.67333221435547\n",
            "Epoch:2 loss is 0.0012728354195132852, train accuracy is 99.22833251953125\n",
            "Epoch:3 loss is 0.0006013456732034683, train accuracy is 99.4433364868164\n",
            "Epoch:4 loss is 0.0012107209768146276, train accuracy is 99.57167053222656\n",
            "Epoch:5 loss is 1.608794991625473e-05, train accuracy is 99.6683349609375\n",
            "Epoch:6 loss is 0.00020626203331630677, train accuracy is 99.74333190917969\n",
            "Epoch:7 loss is 1.2336973668425344e-05, train accuracy is 99.7550048828125\n",
            "Epoch:8 loss is 4.105144398636185e-06, train accuracy is 99.8066635131836\n",
            "Epoch:9 loss is 0.043505843728780746, train accuracy is 99.76499938964844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier_fourhid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() #subclass this model\n",
        "    self.model= nn.Sequential(  #all layers are defined here\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, 100),    # (28-6)-> in each layer we'll be shaping 2 pixel from width and height-> 6---> final size-> 1*28*28-> 10 O/P-> 10 classes\n",
        "        nn.Linear(100,100),\n",
        "        nn.Linear(100,100),\n",
        "        nn.Linear(100,200),\n",
        "        nn.Linear(200,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "#INSTANCE OF NN, LOSS, OPTIMIZER\n",
        "clf = ImageClassifier().to('cuda') #extending to GPU\n",
        "opt = Adam(clf.parameters(), lr=1e-3)\n",
        "loss_fn= nn.CrossEntropyLoss()\n",
        "\n",
        "#Training Flow\n",
        "if __name__ == \"__main__\":\n",
        "  for epoch in range(10):\n",
        "    train_accuracy=0\n",
        "    for batch in train_loader:\n",
        "      X,y= batch\n",
        "      X,y=X.to('cuda'), y.to('cuda')\n",
        "      yhat=clf(X) #prediction\n",
        "      loss= loss_fn(yhat,y)\n",
        "      yhat = yhat.data.max(dim=1, keepdim=True)[1]\n",
        "      train_accuracy += yhat.eq(y.data.view_as(yhat)).cpu().sum()\n",
        "\n",
        "      #apply backpropagation\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step() #gradient descent\n",
        "\n",
        "    train_accuracy = train_accuracy/len(train_loader.dataset)*100\n",
        "    print(f\"Epoch:{epoch} loss is {loss.item()}, train accuracy is {train_accuracy}\")\n",
        "    with open ('model_state.pt','wb') as f:\n",
        "      save(clf.state_dict(),f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNVQkOkI9LRF",
        "outputId": "547e038a-03da-4ada-844c-5603145ff909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 loss is 0.07592614740133286, train accuracy is 96.24500274658203\n",
            "Epoch:1 loss is 0.004146260675042868, train accuracy is 98.6816635131836\n",
            "Epoch:2 loss is 0.0004097092314623296, train accuracy is 99.23999786376953\n",
            "Epoch:3 loss is 0.0009940046584233642, train accuracy is 99.46833038330078\n",
            "Epoch:4 loss is 8.233479456976056e-05, train accuracy is 99.56500244140625\n",
            "Epoch:5 loss is 2.057309575320687e-05, train accuracy is 99.70166778564453\n",
            "Epoch:6 loss is 1.4188201930664945e-05, train accuracy is 99.74666595458984\n",
            "Epoch:7 loss is 3.307941005914472e-05, train accuracy is 99.76333618164062\n",
            "Epoch:8 loss is 7.403718336718157e-05, train accuracy is 99.81500244140625\n",
            "Epoch:9 loss is 8.813471140456386e-06, train accuracy is 99.82499694824219\n"
          ]
        }
      ]
    }
  ]
}